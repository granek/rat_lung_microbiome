# source /opt/conda/bin/activate qiime1
# print_qiime_config.py -t

.ONESHELL:
SHELL = /bin/bash
dir_guard=@mkdir -p $(@D)

# Set Up Paths and Filenames

```{r}
workspace_dir = "workspace"
Sys.setenv(WORKSPACE_DIR=workspace_dir)
Sys.setenv(QIIME_MAP_FILE=file.path(workspace_dir, "rat_lung_qiime_map.tsv"))
Sys.setenv(MAP_FILE=file.path("notes_and_info", "rat_lung_map.tsv"))
Sys.setenv(RAW_DATA_DIR=file.path("raw_data", "160614_McKenney_fastqs"))
Sys.setenv(TAGGED_FASTQ_DIR=file.path(workspace_dir, "tagged_fastq"))
Sys.setenv(CONDA_BIN="/opt/conda/bin")

split_fastq_base = file.path(workspace_dir, "split_fastq")
Sys.setenv(SPLIT_FASTQ_BASE=split_fastq_base)
Sys.setenv(SPLIT_FASTQ_MD5SUM=file.path(split_fastq_base, "split_fastq_md5sum.txt"))
```

SPLIT_FASTQ_BASE := $(WORKSPACE_DIR)/split_fastq
SPLIT_FASTQ_MD5SUM := $(SPLIT_FASTQ_BASE)/split_fastq_md5sum.txt
RESULTS_DIR := results
#--------------------------------------------------
#--------------------------------------------------


# READ1_FASTQ="$(RAW_DATA_DIR)/Undetermined_S0_L001_R1_001.fastq.gz"
# READ2_FASTQ="$RAW_DATA_DIR/Undetermined_S0_L001_R2_001.fastq.gz"
# INDEX_FASTQ="$RAW_DATA_DIR/Undetermined_S0_L001_I1_001.fastq.gz"

FASTQ_PREFIX := $(RAW_DATA_DIR)/Undetermined_S0_L001
FASTQ_SUFFIX := 001.fastq.gz
READ1_FASTQ := $(FASTQ_PREFIX)_R1_$(FASTQ_SUFFIX)
READ2_FASTQ := $(FASTQ_PREFIX)_R2_$(FASTQ_SUFFIX)

#--------------------------------------------------

RAW_FASTQS := $(READ1_FASTQ) $(READ2_FASTQ)
TAGGED_FASTQS := $(addprefix $(TAGGED_FASTQ_DIR)/, $(notdir $(RAW_FASTQS:.fastq.gz=_tagged.fastq)))
SPLIT_FASTQS := $(addprefix $(WORKSPACE_DIR)/split_, $(addsuffix /COMPLETION_STAMP, $(notdir $(RAW_FASTQS:.fastq.gz=))))

#--------------------------------------------------
FULL_PHYLOSEQ_RDS := $(RESULTS_DIR)/rat_lung_ps.rds
#--------------------------------------------------


all : $(TAGGED_FASTQS) $(SPLIT_FASTQS) $(FULL_PHYLOSEQ_RDS)

split_fastqs : $(SPLIT_FASTQS)

demux_checksum : $(SPLIT_FASTQ_MD5SUM)

test : 
	echo $(SPLIT_FASTQS)

# Generate a MAP file that QIIME will accept

```{bash}
sed  '1s/^/#/' $MAP_FILE > $QIIME_MAP_FILE
```

# Generate tagged fastqs
```{bash}
set -u
for RAW_FASTQ in $RAW_DATA_DIR/*_R?_001.fastq.gz; do
  echo $RAW_FASTQ
  FASTQ_BASE=$(basename "$RAW_FASTQ" .fastq.gz)
  echo $FASTQ_BASE
  INDEX_FASTQ="${RAW_FASTQ//_R[1-2]_001/_I1_001}"
  $CONDA_BIN/split_libraries_fastq.py \
    -r 999 -n 999 -q 0 -p 0.0001 \
		--sequence_read_fps $RAW_FASTQ \
		--output_dir $TAGGED_FASTQ_DIR/${FASTQ_BASE} \
		--barcode_read_fps $INDEX_FASTQ \
		--mapping_fps $QIIME_MAP_FILE \
		--barcode_type golay_12 \
		--rev_comp_mapping_barcodes \
		--store_demultiplexed_fastq \
		--retain_unassigned_reads
	mv $TAGGED_FASTQ_DIR/${FASTQ_BASE}/seqs.fastq $TAGGED_FASTQ_DIR/${FASTQ_BASE}_tagged.fastq
	mv $TAGGED_FASTQ_DIR/${FASTQ_BASE}/split_library_log.txt $TAGGED_FASTQ_DIR/${FASTQ_BASE}_split_library_log.txt
  rm -r $TAGGED_FASTQ_DIR/${FASTQ_BASE}
done
```
# WORKS TO HERE
```{bash}
ls -ltr $TAGGED_FASTQ_DIR
date
```
# Split fastqs and gzip
```{bash}
set -u
for TAGGED_FASTQ in $TAGGED_FASTQ_DIR/*.fastq; do
  echo $TAGGED_FASTQ
  FASTQ_BASE=$(basename "$TAGGED_FASTQ" _tagged.fastq)
  echo $FASTQ_BASE
  SPLIT_FASTQ_DIR=${SPLIT_FASTQ_BASE}/${FASTQ_BASE}
  echo $SPLIT_FASTQ_DIR
  ${CONDA_BIN}/split_sequence_file_on_sample_ids.py -i $TAGGED_FASTQ \
					 --file_type fastq \
					 --output_dir $SPLIT_FASTQ_DIR

  for FASTQ in $SPLIT_FASTQ_DIR/*.fastq; do
    gzip --stdout $FASTQ > ${FASTQ}.gz
    rm $FASTQ
  done
done
```

#--------------------------------------------------
$(WORKSPACE_DIR)/split_%/COMPLETION_STAMP : $(TAGGED_FASTQ_DIR)/%_tagged.fastq
	echo $*
	$(CONDA_BIN)/split_sequence_file_on_sample_ids.py -i $(word 1,$^) \
					 --file_type fastq \
					 --output_dir $(@D)
	gzip $(@D)/*.fastq
	touch $@
#--------------------------------------------------
$(SPLIT_FASTQ_MD5SUM) : $(SPLIT_FASTQS)
	echo $^

# Generate MD5SUMs
```{bash}
set -u
cd ${SPLIT_FASTQ_BASE}
md5sum */*.fastq.gz > $(basename $SPLIT_FASTQ_MD5SUM)
```


#--------------------------------------------------
TAXONOMY_DIR := $(WORKSPACE_DIR)/taxonomy_refs
SILVA_DB := $(TAXONOMY_DIR)/silva_nr_v123_train_set.fa.gz

$(FULL_PHYLOSEQ_RDS) : $(SPLIT_FASTQS) $(SILVA_DB)
	$(dir_guard)
	# Rscript --no-restore process_fastq_to_counts.R --quality_plots 5 
	# Rscript --no-restore process_fastq_to_counts.R --filter_fastqs
	Rscript --no-restore process_fastq_to_counts.R


$(SILVA_DB) :
	$(dir_guard)
	wget -O $@_tmp "http://benjjneb.github.io/dada2/Training/silva_nr_v123_train_set.fa.gz"
	mv $@_tmp $@


# mkdir -p $SPLIT_FASTQ_BASE

# validate_mapping_file.py --mapping_fp $QIIME_MAP_FILE --output_dir $WORKSPACE_DIR
# Split without filtering based on <http://benjjneb.github.io/dada2/faq.html>
# for READ in R1 R2
# do
#     split_libraries_fastq.py -r 999 -n 999 -q 0 -p 0.0001 \
# 			     --sequence_read_fps ${FASTQ_PREFIX}_${READ}_001.fastq.gz \
# 			     --output_dir ${LABELED_FASTQ_BASE}_${READ} \
# 			     --barcode_read_fps ${FASTQ_PREFIX}_I1_001.fastq.gz \
# 			     --mapping_fps $QIIME_MAP_FILE \
# 			     --barcode_type golay_12 \
# 			     --rev_comp_mapping_barcodes \
# 			     --store_demultiplexed_fastq \
# 			     --retain_unassigned_reads
    
#     split_sequence_file_on_sample_ids.py -i ${LABEL_FASTQ_BASE}_${READ}/seqs.fastq \
# 					 --file_type fastq \
# 					 --output_dir ${SPLIT_FASTQ_BASE}_${READ}
# done

# split_sequence_file_on_sample_ids.py
# split_sequence_file_on_sample_ids.py -i ~/parker_rat_lung/workspace/split_fastq_R1/seqs.fastq --file_type fastq --output_dir ~/parker_rat_lung/workspace/split_by_id_R1
#--------------------------------------------------------------------------------

# split_libraries_fastq.py OPTIONS
#---------------------------------
# --sample_ids
#     Comma-separated list of samples ids to be applied to all sequences, must be one per input file path (used when data is not multiplexed) [default: None]
# --store_demultiplexed_fastq
#     Write demultiplexed fastq files [default: False]
# --max_barcode_errors
#     Maximum number of errors in barcode [default: 1.5]
# --phred_offset
#     The ascii offset to use when decoding phred scores (either 33 or 64). Warning: in most cases you donâ€™t need to pass this value [default: determined automatically] 
